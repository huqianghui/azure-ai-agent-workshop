{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.base import TaskResult\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv(\"/home/azureuser/azure-ai-agent-workshop/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client=AzureOpenAIChatCompletionClient(\n",
    "            model=os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "            azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "            api_version=os.getenv(\"AZUER_OPENAI_API_VERSION\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Tool\n",
    "async def get_weather(city: str) -> str:\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "\n",
    "# define Agent\n",
    "weather_agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=model_client,\n",
    "    description=\"一个通过使用工具为用户提供天气信息的智能体。\",\n",
    "    system_message=\"你是一个乐于助人的AI智能助手。擅长使用工具解决任务。任务完成后，回复<stop autogenworkshop>\",\n",
    "    tools=[get_weather],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a termination condition. End the conversation if a specific text is mentioned.\n",
    "termination = TextMentionTermination(\"<stop autogenworkshop>\")\n",
    "\n",
    "# Define Team with type set to RoundRobinGroupChat\n",
    "agent_team = RoundRobinGroupChat(participants=[weather_agent], termination_condition=termination, max_turns=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for weather_agent/8875d724-22e8-4002-a7d2-b7bf0c28bcee\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_core/_single_threaded_agent_runtime.py\", line 409, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_core/_base_agent.py\", line 113, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_sequential_routed_agent.py\", line 48, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_core/_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_core/_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_chat_agent_container.py\", line 53, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_agentchat/agents/_assistant_agent.py\", line 330, in on_messages_stream\n",
      "    result = await self._model_client.create(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py\", line 510, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "                                                                     ^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py\", line 1720, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1849, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1543, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1629, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1676, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1629, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1676, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azureuser/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1644, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.InternalServerError: Error code: 500 - {'error': {'message': 'The model produced invalid content. Consider modifying your prompt if you are seeing this error persistently.', 'type': 'model_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1、run() method to run the team\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent_team\u001b[38;5;241m.\u001b[39mrun(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow about the weather of shanghai?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py:261\u001b[0m, in \u001b[0;36mBaseGroupChat.run\u001b[0;34m(self, task, cancellation_token)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run the team and return the result. The base implementation uses\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m:meth:`run_stream` to run the team and then returns the final result.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03mOnce the team is stopped, the termination condition is reset.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m result: TaskResult \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_stream(\n\u001b[1;32m    262\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    263\u001b[0m     cancellation_token\u001b[38;5;241m=\u001b[39mcancellation_token,\n\u001b[1;32m    264\u001b[0m ):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[1;32m    266\u001b[0m         result \u001b[38;5;241m=\u001b[39m message\n",
      "File \u001b[0;32m~/azure-ai-agent-workshop/.venv/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py:417\u001b[0m, in \u001b[0;36mBaseGroupChat.run_stream\u001b[0;34m(self, task, cancellation_token)\u001b[0m\n\u001b[1;32m    415\u001b[0m     cancellation_token\u001b[38;5;241m.\u001b[39mlink_future(message_future)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# Wait for the next message, this will raise an exception if the task is cancelled.\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m message_future\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/asyncio/queues.py:158\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getters\u001b[38;5;241m.\u001b[39mappend(getter)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m getter\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     getter\u001b[38;5;241m.\u001b[39mcancel()  \u001b[38;5;66;03m# Just in case getter is not done yet.\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # 1、run() method to run the team\n",
    "result = await agent_team.run(task=\"how about the weather of shanghai?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='user' models_usage=None content='上海的天气如何?' type='TextMessage'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='weather_agent' models_usage=RequestUsage(prompt_tokens=391, completion_tokens=17) content='上海的天气目前是73华氏度，阳光明媚。' type='TextMessage'\n",
      "source='weather_agent' models_usage=RequestUsage(prompt_tokens=414, completion_tokens=14) content=[FunctionCall(id='call_MRVsoT3ae10yipnbtYWluv8n', arguments='{\"city\":\"上海\"}', name='get_weather')] type='ToolCallRequestEvent'\n",
      "source='weather_agent' models_usage=None content=[FunctionExecutionResult(content='The weather in 上海 is 73 degrees and Sunny.', call_id='call_MRVsoT3ae10yipnbtYWluv8n')] type='ToolCallExecutionEvent'\n",
      "source='weather_agent' models_usage=None content='The weather in 上海 is 73 degrees and Sunny.' type='ToolCallSummaryMessage'\n",
      "source='weather_agent' models_usage=RequestUsage(prompt_tokens=450, completion_tokens=17) content='上海的天气目前是73华氏度，阳光明媚。' type='TextMessage'\n",
      "source='weather_agent' models_usage=RequestUsage(prompt_tokens=473, completion_tokens=17) content='上海的天气目前是73华氏度，阳光明媚。' type='TextMessage'\n",
      "source='weather_agent' models_usage=RequestUsage(prompt_tokens=496, completion_tokens=14) content=[FunctionCall(id='call_oOqayPYaoltvBpdaHUfGDDcW', arguments='{\"city\":\"上海\"}', name='get_weather')] type='ToolCallRequestEvent'\n",
      "source='weather_agent' models_usage=None content=[FunctionExecutionResult(content='The weather in 上海 is 73 degrees and Sunny.', call_id='call_oOqayPYaoltvBpdaHUfGDDcW')] type='ToolCallExecutionEvent'\n",
      "source='weather_agent' models_usage=None content='The weather in 上海 is 73 degrees and Sunny.' type='ToolCallSummaryMessage'\n",
      "source='weather_agent' models_usage=RequestUsage(prompt_tokens=532, completion_tokens=30) content=[FunctionCall(id='call_WzOatVegjwF2b8qqz8Z3o4B7', arguments='{\"city\": \"上海\"}', name='get_weather')] type='ToolCallRequestEvent'\n",
      "source='weather_agent' models_usage=None content=[FunctionExecutionResult(content='The weather in 上海 is 73 degrees and Sunny.', call_id='call_WzOatVegjwF2b8qqz8Z3o4B7')] type='ToolCallExecutionEvent'\n",
      "source='weather_agent' models_usage=None content='The weather in 上海 is 73 degrees and Sunny.' type='ToolCallSummaryMessage'\n",
      "source='weather_agent' models_usage=RequestUsage(prompt_tokens=568, completion_tokens=17) content='上海的天气目前是73华氏度，阳光明媚。' type='TextMessage'\n"
     ]
    }
   ],
   "source": [
    "# 2、run_stream()metho to run team\n",
    "async for message in agent_team.run_stream(task=\"上海的天气如何?\"):\n",
    "    if isinstance(message, TaskResult):\n",
    "        print(\"Stop Reason:\", message.stop_reason)\n",
    "    else:\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- user ----------\n",
      "上海的天气如何?\n",
      "---------- weather_agent ----------\n",
      "[FunctionCall(id='call_f2rANfvvq16VPEHdVTPHPYoP', arguments='{\"city\":\"上海\"}', name='get_weather')]\n",
      "---------- weather_agent ----------\n",
      "[FunctionExecutionResult(content='The weather in 上海 is 73 degrees and Sunny.', call_id='call_f2rANfvvq16VPEHdVTPHPYoP')]\n",
      "---------- weather_agent ----------\n",
      "The weather in 上海 is 73 degrees and Sunny.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- weather_agent ----------\n",
      "上海的天气是73°F（约23°C），阳光明媚。<stop autogenworkshop>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='上海的天气如何?', type='TextMessage'), ToolCallRequestEvent(source='weather_agent', models_usage=RequestUsage(prompt_tokens=234, completion_tokens=14), content=[FunctionCall(id='call_f2rANfvvq16VPEHdVTPHPYoP', arguments='{\"city\":\"上海\"}', name='get_weather')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='weather_agent', models_usage=None, content=[FunctionExecutionResult(content='The weather in 上海 is 73 degrees and Sunny.', call_id='call_f2rANfvvq16VPEHdVTPHPYoP')], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='weather_agent', models_usage=None, content='The weather in 上海 is 73 degrees and Sunny.', type='ToolCallSummaryMessage'), TextMessage(source='weather_agent', models_usage=RequestUsage(prompt_tokens=270, completion_tokens=25), content='上海的天气是73°F（约23°C），阳光明媚。<stop autogenworkshop>', type='TextMessage')], stop_reason=\"Text '<stop autogenworkshop>' mentioned\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method runs the team and uses the official Console tool to output in the proper format\n",
    "# 3、run_stream()\n",
    "stream = agent_team.run_stream(task=\"上海的天气如何?\")\n",
    "await Console(stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
